{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"https://raw.githubusercontent.com/PacktPublishing/Learning-OpenCV-4-Computer-Vision-with-Python-Third-Edition/master/images/statue_small.jpg\",\n",
    "                        stream=True)\n",
    "if response.status_code == 200:\n",
    "    with open(\"../images/statue.jpg\",'wb') as f:\n",
    "        for chunk in response.iter_content(chunk_size=1024):\n",
    "            f.write(chunk)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Pass Filter and Low Pass Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1, -1, -1],\n",
       "       [-1,  8, -1],\n",
       "       [-1, -1, -1]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_3x3  = np.full(shape=(3,3),fill_value=-1)\n",
    "kernel_3x3[1,1] = 8\n",
    "kernel_3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1, -1, -1, -1, -1],\n",
       "       [-1,  1,  2,  1, -1],\n",
       "       [-1,  2,  4,  2, -1],\n",
       "       [-1,  1,  2,  1, -1],\n",
       "       [-1, -1, -1, -1, -1]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_5x5 = np.full(shape=(5,5),fill_value=-1)\n",
    "kernel_5x5[1:4,1:4] = np.array([[1,2,1],\n",
    "                                [2,4,2],\n",
    "                                [1,2,1]])\n",
    "kernel_5x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_image(window_name,img,destroy=False):\n",
    "    cv2.namedWindow(window_name,cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(window_name,img)\n",
    "    if destroy:\n",
    "        cv2.waitKey()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"../images/statue.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "k3 = ndimage.convolve(img,kernel_3x3)\n",
    "k5 = ndimage.convolve(img,kernel_5x5)\n",
    "\n",
    "blurred = cv2.GaussianBlur(img,(17,17),11)\n",
    "g_hpf = img - blurred\n",
    "\n",
    "view_image(\"3x3\",k3)\n",
    "view_image(\"5x5\",k5)\n",
    "view_image(\"blurred\",blurred)\n",
    "view_image(\"g_hpf\",g_hpf)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge Detection\n",
    "\n",
    "1. OpenCV provides many edge-finding filters including \n",
    "   1. Laplacian\n",
    "   2. Sobel\n",
    "   3. Scharr\n",
    "2. These filter turn non0edge region into black and turn the edge region into white.\n",
    "3. However these filter are prone to capture the noise as edge.\n",
    "4. To overcome the drawback we will blur to image to denoise  the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stroke_edge(src,dst,blur_ksize = 7, edge_ksize = 5 ):\n",
    "    view_image(\"source\",src)\n",
    "    # apply blur image\n",
    "    if blur_ksize >= 3:\n",
    "        blurred_src = cv2.medianBlur(src,blur_ksize)\n",
    "        view_image(\"blur\",blurred_src)\n",
    "        gray_src = cv2.cvtColor(blurred_src,code=cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray_src = cv2.cvtColor(src,code=cv2.COLOR_BGR2GRAY)\n",
    "    view_image(\"gray\",gray_src)\n",
    "    # apply edge detector\n",
    "    cv2.Laplacian(gray_src,cv2.CV_8U,gray_src,edge_ksize)\n",
    "    view_image(\"Laplacian\",gray_src)\n",
    "    normalized_inverse_alpha = (1.0/255) * (255 - gray_src)\n",
    "    channels = cv2.split(src)\n",
    "    for channel  in channels:\n",
    "        channel[:] = channel * normalized_inverse_alpha\n",
    "    cv2.merge(channels,dst)   \n",
    "    \n",
    "    view_image(\"final\",dst)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"../images/statue.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke_edge(img,img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_image(\"sfd\",img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Kernel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharpen kernel\n",
    "\n",
    "When the weight kernel sum to 1. then we have the sharpen kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1, -1, -1],\n",
       "       [-1,  9, -1],\n",
       "       [-1, -1, -1]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# central element in the kernel matrix is pixel of interest\n",
    "sharp_kernel = np.full(shape=(3,3),fill_value=-1)\n",
    "sharp_kernel[1,1] = 9\n",
    "sharp_kernel\n",
    "#? if the pixel of interest is already different from its neighbor ,\n",
    "#?  then this difference is intensified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(sharp_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2, -2, -2],\n",
       "       [-2, 17, -2],\n",
       "       [-2, -2, -2]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_sharpen_kernel = np.full(shape=(3,3),fill_value=-2)\n",
    "modified_sharpen_kernel[1,1] = 17\n",
    "modified_sharpen_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"../images/statue.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_image(\"Sharpen\",cv2.filter2D(img,-1,sharp_kernel))\n",
    "view_image(\"modified_sharpen_kernel\",cv2.filter2D(img,-1,modified_sharpen_kernel))\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1, -1, -1],\n",
       "       [-1,  8, -1],\n",
       "       [-1, -1, -1]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_kernel = np.full(shape=(3,3),fill_value=-1)\n",
    "edge_kernel[1,1] = 8\n",
    "edge_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_image(\"original\",img)\n",
    "view_image(\"Sharpen\",cv2.filter2D(img,-1,edge_kernel))\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blur Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04, 0.04, 0.04, 0.04, 0.04],\n",
       "       [0.04, 0.04, 0.04, 0.04, 0.04],\n",
       "       [0.04, 0.04, 0.04, 0.04, 0.04],\n",
       "       [0.04, 0.04, 0.04, 0.04, 0.04],\n",
       "       [0.04, 0.04, 0.04, 0.04, 0.04]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blur_kernel = np.full(shape=(5,5),fill_value=0.04)\n",
    "blur_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_image(\"Blur\",cv2.filter2D(img,-1,blur_kernel),destroy=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emboss Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2, -1,  0],\n",
       "       [-1,  1,  1],\n",
       "       [ 0,  1,  2]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emboss_kernel = np.array([[-2,-1,0],\n",
    "                          [-1,1,1],\n",
    "                          [0,1,2]])\n",
    "emboss_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_image(\"emboss\",cv2.filter2D(img,-1,emboss_kernel),destroy=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canny Edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_image(\"original\",img)\n",
    "view_image(\"Canny\",cv2.Canny(img,200,300))\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv.venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f7542ebe48f9cd7a4d9ff26c2ae67835230f023edebde34cc033d41e4ec18c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
